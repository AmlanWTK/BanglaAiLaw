{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1886b12b-2c61-4a94-afa1-5e6ee90aa6c6",
   "metadata": {},
   "source": [
    "# Importing the Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce2ac864-9c8a-4746-807b-0cab91d12f91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-2.3.2-cp313-cp313-win_amd64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\asus\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\asus\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Downloading pandas-2.3.2-cp313-cp313-win_amd64.whl (11.0 MB)\n",
      "   ---------------------------------------- 0.0/11.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/11.0 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/11.0 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/11.0 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.8/11.0 MB 840.2 kB/s eta 0:00:13\n",
      "   -- ------------------------------------- 0.8/11.0 MB 840.2 kB/s eta 0:00:13\n",
      "   --- ------------------------------------ 1.0/11.0 MB 806.0 kB/s eta 0:00:13\n",
      "   --- ------------------------------------ 1.0/11.0 MB 806.0 kB/s eta 0:00:13\n",
      "   ---- ----------------------------------- 1.3/11.0 MB 784.8 kB/s eta 0:00:13\n",
      "   ----- ---------------------------------- 1.6/11.0 MB 773.1 kB/s eta 0:00:13\n",
      "   ----- ---------------------------------- 1.6/11.0 MB 773.1 kB/s eta 0:00:13\n",
      "   ------ --------------------------------- 1.8/11.0 MB 767.7 kB/s eta 0:00:12\n",
      "   ------ --------------------------------- 1.8/11.0 MB 767.7 kB/s eta 0:00:12\n",
      "   ------- -------------------------------- 2.1/11.0 MB 762.4 kB/s eta 0:00:12\n",
      "   -------- ------------------------------- 2.4/11.0 MB 759.6 kB/s eta 0:00:12\n",
      "   -------- ------------------------------- 2.4/11.0 MB 759.6 kB/s eta 0:00:12\n",
      "   --------- ------------------------------ 2.6/11.0 MB 756.0 kB/s eta 0:00:12\n",
      "   --------- ------------------------------ 2.6/11.0 MB 756.0 kB/s eta 0:00:12\n",
      "   ---------- ----------------------------- 2.9/11.0 MB 753.4 kB/s eta 0:00:11\n",
      "   ----------- ---------------------------- 3.1/11.0 MB 756.9 kB/s eta 0:00:11\n",
      "   ----------- ---------------------------- 3.1/11.0 MB 756.9 kB/s eta 0:00:11\n",
      "   ------------ --------------------------- 3.4/11.0 MB 750.6 kB/s eta 0:00:11\n",
      "   ------------ --------------------------- 3.4/11.0 MB 750.6 kB/s eta 0:00:11\n",
      "   ------------ --------------------------- 3.4/11.0 MB 750.6 kB/s eta 0:00:11\n",
      "   ------------- -------------------------- 3.7/11.0 MB 724.0 kB/s eta 0:00:11\n",
      "   ------------- -------------------------- 3.7/11.0 MB 724.0 kB/s eta 0:00:11\n",
      "   -------------- ------------------------- 3.9/11.0 MB 700.9 kB/s eta 0:00:11\n",
      "   --------------- ------------------------ 4.2/11.0 MB 718.3 kB/s eta 0:00:10\n",
      "   ---------------- ----------------------- 4.5/11.0 MB 731.1 kB/s eta 0:00:09\n",
      "   ---------------- ----------------------- 4.5/11.0 MB 731.1 kB/s eta 0:00:09\n",
      "   ----------------- ---------------------- 4.7/11.0 MB 730.5 kB/s eta 0:00:09\n",
      "   ----------------- ---------------------- 4.7/11.0 MB 730.5 kB/s eta 0:00:09\n",
      "   ------------------ --------------------- 5.0/11.0 MB 724.4 kB/s eta 0:00:09\n",
      "   ------------------- -------------------- 5.2/11.0 MB 728.2 kB/s eta 0:00:08\n",
      "   ------------------- -------------------- 5.2/11.0 MB 728.2 kB/s eta 0:00:08\n",
      "   ------------------- -------------------- 5.2/11.0 MB 728.2 kB/s eta 0:00:08\n",
      "   -------------------- ------------------- 5.5/11.0 MB 705.1 kB/s eta 0:00:08\n",
      "   -------------------- ------------------- 5.5/11.0 MB 705.1 kB/s eta 0:00:08\n",
      "   --------------------- ------------------ 5.8/11.0 MB 706.5 kB/s eta 0:00:08\n",
      "   --------------------- ------------------ 6.0/11.0 MB 719.5 kB/s eta 0:00:07\n",
      "   ---------------------- ----------------- 6.3/11.0 MB 725.0 kB/s eta 0:00:07\n",
      "   ---------------------- ----------------- 6.3/11.0 MB 725.0 kB/s eta 0:00:07\n",
      "   ----------------------- ---------------- 6.6/11.0 MB 725.7 kB/s eta 0:00:07\n",
      "   ----------------------- ---------------- 6.6/11.0 MB 725.7 kB/s eta 0:00:07\n",
      "   ------------------------ --------------- 6.8/11.0 MB 725.5 kB/s eta 0:00:06\n",
      "   ------------------------ --------------- 6.8/11.0 MB 725.5 kB/s eta 0:00:06\n",
      "   ------------------------- -------------- 7.1/11.0 MB 723.9 kB/s eta 0:00:06\n",
      "   -------------------------- ------------- 7.3/11.0 MB 723.6 kB/s eta 0:00:06\n",
      "   -------------------------- ------------- 7.3/11.0 MB 723.6 kB/s eta 0:00:06\n",
      "   --------------------------- ------------ 7.6/11.0 MB 726.0 kB/s eta 0:00:05\n",
      "   ---------------------------- ----------- 7.9/11.0 MB 726.5 kB/s eta 0:00:05\n",
      "   ---------------------------- ----------- 7.9/11.0 MB 726.5 kB/s eta 0:00:05\n",
      "   ----------------------------- ---------- 8.1/11.0 MB 727.7 kB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 8.1/11.0 MB 727.7 kB/s eta 0:00:04\n",
      "   ------------------------------ --------- 8.4/11.0 MB 728.2 kB/s eta 0:00:04\n",
      "   ------------------------------- -------- 8.7/11.0 MB 727.5 kB/s eta 0:00:04\n",
      "   ------------------------------- -------- 8.7/11.0 MB 727.5 kB/s eta 0:00:04\n",
      "   -------------------------------- ------- 8.9/11.0 MB 727.6 kB/s eta 0:00:03\n",
      "   -------------------------------- ------- 8.9/11.0 MB 727.6 kB/s eta 0:00:03\n",
      "   --------------------------------- ------ 9.2/11.0 MB 720.4 kB/s eta 0:00:03\n",
      "   --------------------------------- ------ 9.2/11.0 MB 720.4 kB/s eta 0:00:03\n",
      "   --------------------------------- ------ 9.2/11.0 MB 720.4 kB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 9.4/11.0 MB 713.3 kB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 9.7/11.0 MB 721.5 kB/s eta 0:00:02\n",
      "   ------------------------------------ --- 10.0/11.0 MB 724.2 kB/s eta 0:00:02\n",
      "   ------------------------------------ --- 10.0/11.0 MB 724.2 kB/s eta 0:00:02\n",
      "   ------------------------------------- -- 10.2/11.0 MB 724.8 kB/s eta 0:00:02\n",
      "   -------------------------------------- - 10.5/11.0 MB 726.1 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 10.5/11.0 MB 726.1 kB/s eta 0:00:01\n",
      "   ---------------------------------------  10.7/11.0 MB 725.1 kB/s eta 0:00:01\n",
      "   ---------------------------------------  10.7/11.0 MB 725.1 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.0/11.0 MB 724.1 kB/s eta 0:00:00\n",
      "Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Installing collected packages: pytz, tzdata, pandas\n",
      "\n",
      "   ---------------------------------------- 0/3 [pytz]\n",
      "   ---------------------------------------- 0/3 [pytz]\n",
      "   ------------- -------------------------- 1/3 [tzdata]\n",
      "   ------------- -------------------------- 1/3 [tzdata]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   ---------------------------------------- 3/3 [pandas]\n",
      "\n",
      "Successfully installed pandas-2.3.2 pytz-2025.2 tzdata-2025.2\n",
      "Successfully Installed Pandas\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "! pip install pandas\n",
    "print(\"Successfully Installed Pandas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "985c24cb-5a95-4b4c-a248-539cf43dd196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting PyPDF2\n",
      "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
      "Installing collected packages: PyPDF2\n",
      "Successfully installed PyPDF2-3.0.1\n",
      "Successfully Installed PyPDF2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install PyPDF2\n",
    "print(\"Successfully Installed PyPDF2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9ceea18-ac38-4570-8e38-893f27ec7eb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All successfully imported\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "# For Pdf reading\n",
    "from PyPDF2 import PdfReader\n",
    "\n",
    "# For cleaning\n",
    "import re\n",
    "\n",
    "# Set warnings off\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "print(\"All successfully imported\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87b5953e-e2b2-4afc-82b0-154f06a69382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 46 files to process\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[\"D:\\\\Downloads\\\\BangladeshLaw\\\\1872_ marriedwomen'sproperty_6.pdf\",\n",
       " 'D:\\\\Downloads\\\\BangladeshLaw\\\\1872_christianmarriage_3.pdf',\n",
       " 'D:\\\\Downloads\\\\BangladeshLaw\\\\1872_contract_2.pdf',\n",
       " 'D:\\\\Downloads\\\\BangladeshLaw\\\\1872_foreign_recruting_7.pdf',\n",
       " 'D:\\\\Downloads\\\\BangladeshLaw\\\\1872_majority_9.pdf']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set paths for our project data\n",
    "raw_data_path = \"D:\\Downloads\\BangladeshLaw\"\n",
    "processed_data_path = \"D:/Law-RAG/data/processed\"\n",
    "\n",
    "# Create processed folder if it doesn't exist\n",
    "os.makedirs(processed_data_path, exist_ok=True)\n",
    "\n",
    "# List all PDF/TXT files in raw data\n",
    "file_list = glob.glob(os.path.join(raw_data_path, \"*.pdf\")) + \\\n",
    "            glob.glob(os.path.join(raw_data_path, \"*.txt\"))\n",
    "\n",
    "print(f\"Found {len(file_list)} files to process\")\n",
    "file_list[:5]  # show first 5 files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad3d654c-d58f-4114-af35-7fe30ec2462c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pdf2image\n",
      "  Using cached pdf2image-1.17.0-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting pytesseract\n",
      "  Using cached pytesseract-0.3.13-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: pillow in c:\\users\\asus\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pdf2image) (11.3.0)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\asus\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pytesseract) (25.0)\n",
      "Using cached pdf2image-1.17.0-py3-none-any.whl (11 kB)\n",
      "Using cached pytesseract-0.3.13-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: pytesseract, pdf2image\n",
      "\n",
      "   -------------------- ------------------- 1/2 [pdf2image]\n",
      "   ---------------------------------------- 2/2 [pdf2image]\n",
      "\n",
      "Successfully installed pdf2image-1.17.0 pytesseract-0.3.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "! pip install pdf2image pytesseract\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b2693c-1a21-48eb-bff9-ba04efb210ac",
   "metadata": {},
   "source": [
    "## Extracting Text from Scanned PDFs Using OCR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f695789a-3c9a-4334-808d-95e1e3996301",
   "metadata": {},
   "source": [
    "This code converts each page of a scanned PDF into an image using pdf2image and Poppler.\n",
    "Then it applies Tesseract OCR to recognize and extract text from those images.\n",
    "Finally, it combines the extracted text into a single string for further use or analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4245aff-4da9-4091-90cf-f9df7e9a2678",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/08/2025 The Married Women's Property Act, 1874\n",
      "\n",
      "The Married Women's Property Act, 1874\n",
      "(ACT NO. Ill OF 1874 )\n",
      "\n",
      "2#An Act to explain and amend the law relating to certain married women, and for other purposes.\n",
      "\n",
      "Preamble\n",
      "\n",
      "WHEREAS it is expedient to make such provision as hereinafter appears for the enjoyment of wages and earnings by women\n",
      "married before the first day of January, 1866, and for insurances on lives by persons married before or after that day:\n",
      "\n",
      "And whereas by the [Succession Act, 19\n"
     ]
    }
   ],
   "source": [
    "from pdf2image import convert_from_path\n",
    "import pytesseract\n",
    "\n",
    "pytesseract.pytesseract.tesseract_cmd = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\"\n",
    "\n",
    "def read_pdf_ocr(file_path):\n",
    "    \"\"\"\n",
    "    Reads a scanned PDF using OCR and returns combined text\n",
    "    \"\"\"\n",
    "    text = \"\"\n",
    "    pages = convert_from_path(file_path, dpi=300, poppler_path=r\"D:\\Downloads\\Release-25.07.0-0\\poppler-25.07.0\\Library\\bin\")\n",
    "    for page in pages:\n",
    "        text += pytesseract.image_to_string(page, lang='eng') + \"\\n\"\n",
    "    return text\n",
    "\n",
    "# Test\n",
    "sample_pdf = [f for f in file_list if f.endswith(\".pdf\")][0]\n",
    "sample_text = read_pdf_ocr(sample_pdf)\n",
    "print(sample_text[:500])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "feb298a5-9aff-4669-8ca1-97cbf450d48b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: fitz 0.0.1.dev2\n",
      "Uninstalling fitz-0.0.1.dev2:\n",
      "  Successfully uninstalled fitz-0.0.1.dev2\n"
     ]
    }
   ],
   "source": [
    "! pip uninstall fitz -y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a0c4dba9-814b-442d-9253-4d11480e49ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting PyMuPDF\n",
      "  Using cached pymupdf-1.26.4-cp39-abi3-win_amd64.whl.metadata (3.4 kB)\n",
      "Using cached pymupdf-1.26.4-cp39-abi3-win_amd64.whl (18.7 MB)\n",
      "Installing collected packages: PyMuPDF\n",
      "Successfully installed PyMuPDF-1.26.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "! pip install PyMuPDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "308909fd-46fd-43fb-a0a5-8f5f90c695e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 46 PDF files to process\n",
      "✅ Saved OCR text for: 1872_ marriedwomen'sproperty_6.pdf\n",
      "✅ Saved OCR text for: 1872_christianmarriage_3.pdf\n",
      "✅ Saved OCR text for: 1872_contract_2.pdf\n",
      "✅ Saved OCR text for: 1872_foreign_recruting_7.pdf\n",
      "✅ Saved OCR text for: 1872_majority_9.pdf\n",
      "✅ Saved OCR text for: 1872_marriage_1.pdf\n",
      "✅ Saved OCR text for: 1872_oaths_5.pdf\n",
      "✅ Saved OCR text for: 1872_savingbanks_4.pdf\n",
      "✅ Saved OCR text for: 1872_survey_8.pdf\n",
      "✅ Saved OCR text for: 1875_law_reports_1.pdf\n",
      "✅ Saved OCR text for: 1876_irrigation_1.pdf\n",
      "✅ Saved OCR text for: 1877_specific_1.pdf\n",
      "✅ Saved OCR text for: 1878_arms_1.pdf\n",
      "✅ Saved OCR text for: 1878_tresuretrove_1.pdf\n",
      "✅ Saved OCR text for: 1879_court_of_wards_1.pdf\n",
      "✅ Saved OCR text for: 1879_touts_1.pdf\n",
      "✅ Saved OCR text for: 1880_kazis_3.pdf\n",
      "✅ Saved OCR text for: 1880_religious_societies_1.pdf\n",
      "✅ Saved OCR text for: 1880_vaccination_2.pdf\n",
      "✅ Saved OCR text for: 1881_chittagong_hill_tracts_police_regulation_1.pdf\n",
      "✅ Saved OCR text for: 1881_municipal_taxation_2.pdf\n",
      "✅ Saved OCR text for: 1881_negotiable_instruments_4.pdf\n",
      "✅ Saved OCR text for: 1881_obstructions_in_fairway_3.pdf\n",
      "✅ Saved OCR text for: 1882_easements_2.pdf\n",
      "✅ Saved OCR text for: 1882_property_1.pdf\n",
      "✅ Saved OCR text for: 1882_trusts_1.pdf\n",
      "✅ Saved OCR text for: 1883_land_improvement_loan_1.pdf\n",
      "✅ Saved OCR text for: 1884_agriculturist's_loan_1.pdf\n",
      "✅ Saved OCR text for: 1884_explosive_1.pdf\n",
      "✅ Saved OCR text for: 1885_ferries_1.pdf\n",
      "✅ Saved OCR text for: 1885_telefraph_2.pdf\n",
      "✅ Saved OCR text for: 1886_birth_deaths_marriage_1.pdf\n",
      "✅ Saved OCR text for: 1887_civil_courst_2.pdf\n",
      "✅ Saved OCR text for: 1887_small_cause_courts_1.pdf\n",
      "✅ Saved OCR text for: 1887_suits_valuation_1.pdf\n",
      "✅ Saved OCR text for: 1889_metal_tokens_1.pdf\n",
      "✅ Saved OCR text for: 1889_private_fisheries_protection_2.pdf\n",
      "✅ Saved OCR text for: 1890_charitable_.endowments_1.pdf\n",
      "✅ Saved OCR text for: 1890_excise_malt_liquors_2.pdf\n",
      "✅ Saved OCR text for: 1890_guradians_and_ward_1.pdf\n",
      "✅ Saved OCR text for: 1890_railway_act_1.pdf\n",
      "✅ Saved OCR text for: 1893_partition_act_1.pdf\n",
      "✅ Saved OCR text for: 1894_prisions_1.pdf\n",
      "✅ Saved OCR text for: 1895_government_grants_1.pdf\n",
      "✅ Saved OCR text for: 1896_the protection_of_muslim_pilgrims_1.pdf\n",
      "✅ Saved OCR text for: 1897_general_clause_1.pdf\n"
     ]
    }
   ],
   "source": [
    "# 📌 Cell: OCR PDFs and save as TXT (Robust Version with Absolute Paths)\n",
    "import os\n",
    "import fitz  # pip install PyMuPDF\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "\n",
    "# ✅ Absolute folder paths\n",
    "raw_folder = r\"D:\\Downloads\\BangladeshLaw\"\n",
    "processed_folder = r\"D:\\Law-RAG\\data\\processed\"\n",
    "\n",
    "# ✅ Create folders if they don't exist\n",
    "os.makedirs(raw_folder, exist_ok=True)\n",
    "os.makedirs(processed_folder, exist_ok=True)\n",
    "\n",
    "# ✅ Get all PDF files in raw folder\n",
    "pdf_files = [os.path.join(raw_folder, f) for f in os.listdir(raw_folder) if f.endswith(\".pdf\")]\n",
    "print(f\"Found {len(pdf_files)} PDF files to process\")\n",
    "\n",
    "# ✅ Loop through PDFs and save OCR text\n",
    "for pdf_file in pdf_files:\n",
    "    try:\n",
    "        doc = fitz.open(pdf_file)\n",
    "        text = \"\"\n",
    "        for page in doc:\n",
    "            # Convert page to image\n",
    "            pix = page.get_pixmap(dpi=300)\n",
    "            img = Image.frombytes(\"RGB\", [pix.width, pix.height], pix.samples)\n",
    "            # OCR using pytesseract\n",
    "            page_text = pytesseract.image_to_string(img, lang='eng')  # change 'eng' if needed\n",
    "            text += page_text + \"\\n\"\n",
    "\n",
    "        # Save OCR text as TXT\n",
    "        txt_file_name = os.path.join(processed_folder, os.path.basename(pdf_file).replace(\".pdf\", \".txt\"))\n",
    "        with open(txt_file_name, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(text)\n",
    "\n",
    "        print(f\"✅ Saved OCR text for: {os.path.basename(pdf_file)}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"⚠ Skipping {os.path.basename(pdf_file)} due to error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cfa7aeae-e979-417f-8f4e-fab68e37aeec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 46 TXT files to read\n",
      "✅ All TXT files read and cleaned!\n",
      "Sample text from first file:\n",
      "30/08/2025 The Married Women's Property Act, 1874 The Married Women's Property Act, 1874 (ACT NO. Ill OF 1874 ) 2#An Act to explain and amend the law relating to certain married women, and for other purposes. Preamble WHEREAS it is expedient to make such provision as hereinafter appears for the enjoyment of wages and earnings by women married before the first day of January, 1866, and for insurances on lives by persons married before or after that day: And whereas by the [Succession Act, 1925], \n"
     ]
    }
   ],
   "source": [
    "# 📌 Cell 5: Read processed TXT files and preprocess\n",
    "import os\n",
    "import re\n",
    "\n",
    "processed_folder = r\"D:\\Law-RAG\\data\\processed\"\n",
    "\n",
    "# Get all TXT files\n",
    "txt_files = [os.path.join(processed_folder, f) for f in os.listdir(processed_folder) if f.endswith(\".txt\")]\n",
    "print(f\"Found {len(txt_files)} TXT files to read\")\n",
    "\n",
    "# Function to clean text\n",
    "def clean_text(text):\n",
    "    # Remove multiple spaces, newlines\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    # Optional: remove non-ascii chars\n",
    "    text = re.sub(r'[^\\x00-\\x7F]+', ' ', text)\n",
    "    return text.strip()\n",
    "\n",
    "# Read and preprocess all TXT files\n",
    "all_texts = {}\n",
    "for txt_file in txt_files:\n",
    "    with open(txt_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        text = f.read()\n",
    "        clean = clean_text(text)\n",
    "        all_texts[os.path.basename(txt_file)] = clean\n",
    "\n",
    "print(\"✅ All TXT files read and cleaned!\")\n",
    "print(\"Sample text from first file:\")\n",
    "first_file = list(all_texts.keys())[0]\n",
    "print(all_texts[first_file][:500])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d95d997c-2dbc-4cea-ab67-1ea2323e58dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Chunking complete! Created 2260 chunks from 46 documents.\n",
      "Sample chunks from first file:\n",
      "\n",
      "--- Chunk 1 ---\n",
      "30/08/2025 The Married Women's Property Act, 1874 The Married Women's Property Act, 1874 (ACT NO. Ill OF 1874 ) 2#An Act to explain and amend the law relating to certain married women, and for other purposes. Preamble WHEREAS it is expedient to make such provision as hereinafter appears for the enjoyment of wages and earnings by women married before the first day of January, 1866, and for insuranc...\n",
      "\n",
      "--- Chunk 2 ---\n",
      "e person whom he or she marries, nor become incapable of doing any act in respect of his or her own property, which he or she could have done, if unmarried: And whereas by force of the said Act all women to whose marriages it applies are absolute owners of all property vested in, or acquired by, them, and their husbands do not by their marriage acquire any interest in such property, but the said A...\n",
      "\n",
      "--- Chunk 3 ---\n",
      "ves: CHAPTER | PRELIMINARY Short title 1. This Act may be called the Married Women's Property Act, 1874. Extent and 2. It extends to the whole of Bangladesh. application bdlaws.minlaw.gov.bd/act-print-30.html 1/6 30/08/2025 [Repealed] Married women's earnings to be their separate property bdlaws.minlaw.gov.bd/act-print-30.html The Married Women's Property Act, 1874 But nothing herein contained app...\n"
     ]
    }
   ],
   "source": [
    "# 📌 Cell 6: Chunking the cleaned text\n",
    "def chunk_text(text, chunk_size=800, overlap=200):\n",
    "    \"\"\"\n",
    "    Splits text into chunks with overlap for context.\n",
    "    Example: If chunk_size=800 and overlap=200, \n",
    "    each chunk will have 800 chars but 200 chars overlap with previous.\n",
    "    \"\"\"\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    while start < len(text):\n",
    "        end = start + chunk_size\n",
    "        chunk = text[start:end]\n",
    "        chunks.append(chunk.strip())\n",
    "        start += chunk_size - overlap  # move by chunk_size - overlap\n",
    "    return chunks\n",
    "\n",
    "# Apply chunking to all cleaned texts\n",
    "chunked_texts = {}\n",
    "total_chunks = 0\n",
    "for filename, text in all_texts.items():\n",
    "    chunks = chunk_text(text)\n",
    "    chunked_texts[filename] = chunks\n",
    "    total_chunks += len(chunks)\n",
    "\n",
    "print(f\"✅ Chunking complete! Created {total_chunks} chunks from {len(all_texts)} documents.\")\n",
    "print(\"Sample chunks from first file:\")\n",
    "first_file = list(chunked_texts.keys())[0]\n",
    "for i, chunk in enumerate(chunked_texts[first_file][:3]):  # show first 3 chunks\n",
    "    print(f\"\\n--- Chunk {i+1} ---\\n{chunk[:400]}...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dea97a57-6042-4bd7-8380-05e172e021f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence-transformers\n",
      "  Using cached sentence_transformers-5.1.0-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting transformers<5.0.0,>=4.41.0 (from sentence-transformers)\n",
      "  Using cached transformers-4.56.1-py3-none-any.whl.metadata (42 kB)\n",
      "Collecting tqdm (from sentence-transformers)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sentence-transformers) (2.8.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\asus\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sentence-transformers) (1.6.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\asus\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sentence-transformers) (1.15.2)\n",
      "Collecting huggingface-hub>=0.20.0 (from sentence-transformers)\n",
      "  Using cached huggingface_hub-0.34.4-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: Pillow in c:\\users\\asus\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sentence-transformers) (11.3.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sentence-transformers) (4.12.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\asus\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (3.19.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\asus\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.2.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (6.0.2)\n",
      "Collecting regex!=2019.12.17 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Downloading regex-2025.9.1-cp313-cp313-win_amd64.whl.metadata (41 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\asus\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.32.3)\n",
      "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Using cached tokenizers-0.22.0-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Using cached safetensors-0.6.2-cp38-abi3-win_amd64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.7.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\asus\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\asus\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\asus\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\asus\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (80.9.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\asus\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\asus\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\asus\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\asus\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.8.30)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "Using cached sentence_transformers-5.1.0-py3-none-any.whl (483 kB)\n",
      "Using cached transformers-4.56.1-py3-none-any.whl (11.6 MB)\n",
      "Using cached huggingface_hub-0.34.4-py3-none-any.whl (561 kB)\n",
      "Using cached tokenizers-0.22.0-cp39-abi3-win_amd64.whl (2.7 MB)\n",
      "Downloading regex-2025.9.1-cp313-cp313-win_amd64.whl (275 kB)\n",
      "Using cached safetensors-0.6.2-cp38-abi3-win_amd64.whl (320 kB)\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: tqdm, safetensors, regex, huggingface-hub, tokenizers, transformers, sentence-transformers\n",
      "\n",
      "   ---------------------------------------- 0/7 [tqdm]\n",
      "   ---------------------------------------- 0/7 [tqdm]\n",
      "   ---------------------------------------- 0/7 [tqdm]\n",
      "   ----- ---------------------------------- 1/7 [safetensors]\n",
      "   ----------- ---------------------------- 2/7 [regex]\n",
      "   ----------------- ---------------------- 3/7 [huggingface-hub]\n",
      "   ----------------- ---------------------- 3/7 [huggingface-hub]\n",
      "   ----------------- ---------------------- 3/7 [huggingface-hub]\n",
      "   ----------------- ---------------------- 3/7 [huggingface-hub]\n",
      "   ----------------- ---------------------- 3/7 [huggingface-hub]\n",
      "   ----------------- ---------------------- 3/7 [huggingface-hub]\n",
      "   ----------------- ---------------------- 3/7 [huggingface-hub]\n",
      "   ----------------- ---------------------- 3/7 [huggingface-hub]\n",
      "   ----------------- ---------------------- 3/7 [huggingface-hub]\n",
      "   ----------------- ---------------------- 3/7 [huggingface-hub]\n",
      "   ----------------- ---------------------- 3/7 [huggingface-hub]\n",
      "   ----------------- ---------------------- 3/7 [huggingface-hub]\n",
      "   ----------------- ---------------------- 3/7 [huggingface-hub]\n",
      "   ----------------- ---------------------- 3/7 [huggingface-hub]\n",
      "   ----------------- ---------------------- 3/7 [huggingface-hub]\n",
      "   ----------------- ---------------------- 3/7 [huggingface-hub]\n",
      "   ----------------- ---------------------- 3/7 [huggingface-hub]\n",
      "   ----------------- ---------------------- 3/7 [huggingface-hub]\n",
      "   ----------------- ---------------------- 3/7 [huggingface-hub]\n",
      "   ----------------- ---------------------- 3/7 [huggingface-hub]\n",
      "   ---------------------- ----------------- 4/7 [tokenizers]\n",
      "   ---------------------- ----------------- 4/7 [tokenizers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [sentence-transformers]\n",
      "   ---------------------------------- ----- 6/7 [sentence-transformers]\n",
      "   ---------------------------------- ----- 6/7 [sentence-transformers]\n",
      "   ---------------------------------- ----- 6/7 [sentence-transformers]\n",
      "   ---------------------------------- ----- 6/7 [sentence-transformers]\n",
      "   ---------------------------------- ----- 6/7 [sentence-transformers]\n",
      "   ---------------------------------- ----- 6/7 [sentence-transformers]\n",
      "   ---------------------------------- ----- 6/7 [sentence-transformers]\n",
      "   ---------------------------------- ----- 6/7 [sentence-transformers]\n",
      "   ---------------------------------- ----- 6/7 [sentence-transformers]\n",
      "   ---------------------------------- ----- 6/7 [sentence-transformers]\n",
      "   ---------------------------------- ----- 6/7 [sentence-transformers]\n",
      "   ---------------------------------- ----- 6/7 [sentence-transformers]\n",
      "   ---------------------------------- ----- 6/7 [sentence-transformers]\n",
      "   ---------------------------------- ----- 6/7 [sentence-transformers]\n",
      "   ---------------------------------- ----- 6/7 [sentence-transformers]\n",
      "   ---------------------------------- ----- 6/7 [sentence-transformers]\n",
      "   ---------------------------------- ----- 6/7 [sentence-transformers]\n",
      "   ---------------------------------------- 7/7 [sentence-transformers]\n",
      "\n",
      "Successfully installed huggingface-hub-0.34.4 regex-2025.9.1 safetensors-0.6.2 sentence-transformers-5.1.0 tokenizers-0.22.0 tqdm-4.67.1 transformers-4.56.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "! pip install sentence-transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fada7d1d-9482-4599-88de-6d64177691a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (2, 384)\n",
      "First embedding vector (truncated): [-0.0344772   0.03102322  0.006735    0.02610897 -0.03936201 -0.16030249\n",
      "  0.06692398 -0.00644147 -0.04745052  0.01475886]\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load small fast model\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Test sentences\n",
    "sentences = [\"Hello world\", \"Testing embeddings\"]\n",
    "\n",
    "# Generate embeddings\n",
    "embeddings = model.encode(sentences)\n",
    "\n",
    "print(\"Shape:\", embeddings.shape)\n",
    "print(\"First embedding vector (truncated):\", embeddings[0][:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ac2c869-630b-4d5b-9be4-30ec97114b05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding 1872_ marriedwomen'sproperty_6.txt with 16 chunks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|███████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding 1872_christianmarriage_3.txt with 95 chunks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|███████████████████████████████████████████████████████████████████████████| 6/6 [00:03<00:00,  1.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding 1872_contract_2.txt with 0 chunks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding 1872_foreign_recruting_7.txt with 6 chunks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|███████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding 1872_majority_9.txt with 6 chunks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|███████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  3.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding 1872_marriage_1.txt with 25 chunks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|███████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  2.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding 1872_oaths_5.txt with 14 chunks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|███████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding 1872_savingbanks_4.txt with 17 chunks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|███████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  3.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding 1872_survey_8.txt with 99 chunks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|███████████████████████████████████████████████████████████████████████████| 7/7 [00:03<00:00,  2.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding 1875_law_reports_1.txt with 3 chunks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|███████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding 1876_irrigation_1.txt with 115 chunks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|███████████████████████████████████████████████████████████████████████████| 8/8 [00:03<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding 1877_specific_1.txt with 136 chunks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|███████████████████████████████████████████████████████████████████████████| 9/9 [00:05<00:00,  1.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding 1878_arms_1.txt with 55 chunks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|███████████████████████████████████████████████████████████████████████████| 4/4 [00:01<00:00,  2.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding 1878_tresuretrove_1.txt with 23 chunks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|███████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  2.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding 1879_court_of_wards_1.txt with 113 chunks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|███████████████████████████████████████████████████████████████████████████| 8/8 [00:03<00:00,  2.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding 1879_touts_1.txt with 15 chunks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|███████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding 1880_kazis_3.txt with 8 chunks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|███████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  3.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding 1880_religious_societies_1.txt with 12 chunks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|███████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding 1880_vaccination_2.txt with 46 chunks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|███████████████████████████████████████████████████████████████████████████| 3/3 [00:01<00:00,  1.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding 1881_chittagong_hill_tracts_police_regulation_1.txt with 17 chunks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|███████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  3.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding 1881_municipal_taxation_2.txt with 8 chunks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|███████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  3.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding 1881_negotiable_instruments_4.txt with 170 chunks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|█████████████████████████████████████████████████████████████████████████| 11/11 [00:06<00:00,  1.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding 1881_obstructions_in_fairway_3.txt with 12 chunks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|███████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding 1882_easements_2.txt with 105 chunks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|███████████████████████████████████████████████████████████████████████████| 7/7 [00:04<00:00,  1.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding 1882_property_1.txt with 252 chunks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|█████████████████████████████████████████████████████████████████████████| 16/16 [00:09<00:00,  1.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding 1882_trusts_1.txt with 135 chunks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|███████████████████████████████████████████████████████████████████████████| 9/9 [00:04<00:00,  1.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding 1883_land_improvement_loan_1.txt with 18 chunks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|███████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  3.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding 1884_agriculturist's_loan_1.txt with 5 chunks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|███████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding 1884_explosive_1.txt with 42 chunks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|███████████████████████████████████████████████████████████████████████████| 3/3 [00:01<00:00,  1.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding 1885_ferries_1.txt with 35 chunks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|███████████████████████████████████████████████████████████████████████████| 3/3 [00:01<00:00,  2.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding 1885_telefraph_2.txt with 57 chunks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|███████████████████████████████████████████████████████████████████████████| 4/4 [00:01<00:00,  2.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding 1886_birth_deaths_marriage_1.txt with 17 chunks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|███████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  3.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding 1887_civil_courst_2.txt with 54 chunks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|███████████████████████████████████████████████████████████████████████████| 4/4 [00:01<00:00,  2.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding 1887_small_cause_courts_1.txt with 34 chunks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|███████████████████████████████████████████████████████████████████████████| 3/3 [00:01<00:00,  2.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding 1887_suits_valuation_1.txt with 13 chunks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|███████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding 1889_metal_tokens_1.txt with 11 chunks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|███████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding 1889_private_fisheries_protection_2.txt with 6 chunks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|███████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  5.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding 1890_charitable_.endowments_1.txt with 22 chunks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|███████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  2.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding 1890_excise_malt_liquors_2.txt with 3 chunks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|███████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding 1890_guradians_and_ward_1.txt with 75 chunks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|███████████████████████████████████████████████████████████████████████████| 5/5 [00:02<00:00,  1.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding 1890_railway_act_1.txt with 184 chunks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|█████████████████████████████████████████████████████████████████████████| 12/12 [00:06<00:00,  1.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding 1893_partition_act_1.txt with 11 chunks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|███████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding 1894_prisions_1.txt with 68 chunks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|███████████████████████████████████████████████████████████████████████████| 5/5 [00:02<00:00,  2.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding 1895_government_grants_1.txt with 4 chunks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|███████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding 1896_the protection_of_muslim_pilgrims_1.txt with 14 chunks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|███████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding 1897_general_clause_1.txt with 84 chunks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|███████████████████████████████████████████████████████████████████████████| 6/6 [00:03<00:00,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "embed_model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "all_embeddings = {}\n",
    "for filename, chunks in chunked_texts.items():\n",
    "    print(f\"Embedding {filename} with {len(chunks)} chunks...\")\n",
    "    embeddings = embed_model.encode(chunks, batch_size=16, show_progress_bar=True)\n",
    "    all_embeddings[filename] = embeddings\n",
    "print(\"Embeddings completed\")    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4bf60b9c-6852-483f-9f97-4a597bbea7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save embeddings as numpy files for persistence\n",
    "import os\n",
    "\n",
    "os.makedirs(\"data/embeddings\", exist_ok=True)\n",
    "\n",
    "for filename, embeddings in all_embeddings.items():\n",
    "    np.save(f\"data/embeddings/{filename}_embeddings.npy\", embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "14c6739f-0925-4e86-b7d9-2c48c6777817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"1872_ marriedwomen'sproperty_6.txt_embeddings.npy\", '1872_christianmarriage_3.txt_embeddings.npy', '1872_contract_2.txt_embeddings.npy', '1872_foreign_recruting_7.txt_embeddings.npy', '1872_majority_9.txt_embeddings.npy', '1872_marriage_1.txt_embeddings.npy', '1872_oaths_5.txt_embeddings.npy', '1872_savingbanks_4.txt_embeddings.npy', '1872_survey_8.txt_embeddings.npy', '1875_law_reports_1.txt_embeddings.npy', '1876_irrigation_1.txt_embeddings.npy', '1877_specific_1.txt_embeddings.npy', '1878_arms_1.txt_embeddings.npy', '1878_tresuretrove_1.txt_embeddings.npy', '1879_court_of_wards_1.txt_embeddings.npy', '1879_touts_1.txt_embeddings.npy', '1880_kazis_3.txt_embeddings.npy', '1880_religious_societies_1.txt_embeddings.npy', '1880_vaccination_2.txt_embeddings.npy', '1881_chittagong_hill_tracts_police_regulation_1.txt_embeddings.npy', '1881_municipal_taxation_2.txt_embeddings.npy', '1881_negotiable_instruments_4.txt_embeddings.npy', '1881_obstructions_in_fairway_3.txt_embeddings.npy', '1882_easements_2.txt_embeddings.npy', '1882_property_1.txt_embeddings.npy', '1882_trusts_1.txt_embeddings.npy', '1883_land_improvement_loan_1.txt_embeddings.npy', \"1884_agriculturist's_loan_1.txt_embeddings.npy\", '1884_explosive_1.txt_embeddings.npy', '1885_ferries_1.txt_embeddings.npy', '1885_telefraph_2.txt_embeddings.npy', '1886_birth_deaths_marriage_1.txt_embeddings.npy', '1887_civil_courst_2.txt_embeddings.npy', '1887_small_cause_courts_1.txt_embeddings.npy', '1887_suits_valuation_1.txt_embeddings.npy', '1889_metal_tokens_1.txt_embeddings.npy', '1889_private_fisheries_protection_2.txt_embeddings.npy', '1890_charitable_.endowments_1.txt_embeddings.npy', '1890_excise_malt_liquors_2.txt_embeddings.npy', '1890_guradians_and_ward_1.txt_embeddings.npy', '1890_railway_act_1.txt_embeddings.npy', '1893_partition_act_1.txt_embeddings.npy', '1894_prisions_1.txt_embeddings.npy', '1895_government_grants_1.txt_embeddings.npy', '1896_the protection_of_muslim_pilgrims_1.txt_embeddings.npy', '1897_general_clause_1.txt_embeddings.npy']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# List all files inside embeddings folder\n",
    "print(os.listdir(\"data/embeddings\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec04ee32-39c3-4ff7-a150-66f245afe074",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting faiss-cpu\n",
      "  Downloading faiss_cpu-1.12.0-cp313-cp313-win_amd64.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from faiss-cpu) (2.2.5)\n",
      "Requirement already satisfied: packaging in c:\\users\\asus\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from faiss-cpu) (25.0)\n",
      "Downloading faiss_cpu-1.12.0-cp313-cp313-win_amd64.whl (18.2 MB)\n",
      "   ---------------------------------------- 0.0/18.2 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/18.2 MB ? eta -:--:--\n",
      "   --------- ------------------------------ 4.2/18.2 MB 16.3 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 12.6/18.2 MB 28.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 18.2/18.2 MB 30.5 MB/s  0:00:00\n",
      "Installing collected packages: faiss-cpu\n",
      "Successfully installed faiss-cpu-1.12.0\n",
      "Successfully installed faiss\n"
     ]
    }
   ],
   "source": [
    "! pip install faiss-cpu\n",
    "print(\"Successfully installed faiss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "97c193ba-014a-4c82-8a29-da90591a1d45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Embedding dimensions per file:\n",
      "1872_ marriedwomen'sproperty_6.txt_embeddings.npy: (16, 384)\n",
      "1872_christianmarriage_3.txt_embeddings.npy: (95, 384)\n",
      "1872_contract_2.txt_embeddings.npy: (1, 0)\n",
      "1872_foreign_recruting_7.txt_embeddings.npy: (6, 384)\n",
      "1872_majority_9.txt_embeddings.npy: (6, 384)\n",
      "1872_marriage_1.txt_embeddings.npy: (25, 384)\n",
      "1872_oaths_5.txt_embeddings.npy: (14, 384)\n",
      "1872_savingbanks_4.txt_embeddings.npy: (17, 384)\n",
      "1872_survey_8.txt_embeddings.npy: (99, 384)\n",
      "1875_law_reports_1.txt_embeddings.npy: (3, 384)\n",
      "1876_irrigation_1.txt_embeddings.npy: (115, 384)\n",
      "1877_specific_1.txt_embeddings.npy: (136, 384)\n",
      "1878_arms_1.txt_embeddings.npy: (55, 384)\n",
      "1878_tresuretrove_1.txt_embeddings.npy: (23, 384)\n",
      "1879_court_of_wards_1.txt_embeddings.npy: (113, 384)\n",
      "1879_touts_1.txt_embeddings.npy: (15, 384)\n",
      "1880_kazis_3.txt_embeddings.npy: (8, 384)\n",
      "1880_religious_societies_1.txt_embeddings.npy: (12, 384)\n",
      "1880_vaccination_2.txt_embeddings.npy: (46, 384)\n",
      "1881_chittagong_hill_tracts_police_regulation_1.txt_embeddings.npy: (17, 384)\n",
      "1881_municipal_taxation_2.txt_embeddings.npy: (8, 384)\n",
      "1881_negotiable_instruments_4.txt_embeddings.npy: (170, 384)\n",
      "1881_obstructions_in_fairway_3.txt_embeddings.npy: (12, 384)\n",
      "1882_easements_2.txt_embeddings.npy: (105, 384)\n",
      "1882_property_1.txt_embeddings.npy: (252, 384)\n",
      "1882_trusts_1.txt_embeddings.npy: (135, 384)\n",
      "1883_land_improvement_loan_1.txt_embeddings.npy: (18, 384)\n",
      "1884_agriculturist's_loan_1.txt_embeddings.npy: (5, 384)\n",
      "1884_explosive_1.txt_embeddings.npy: (42, 384)\n",
      "1885_ferries_1.txt_embeddings.npy: (35, 384)\n",
      "1885_telefraph_2.txt_embeddings.npy: (57, 384)\n",
      "1886_birth_deaths_marriage_1.txt_embeddings.npy: (17, 384)\n",
      "1887_civil_courst_2.txt_embeddings.npy: (54, 384)\n",
      "1887_small_cause_courts_1.txt_embeddings.npy: (34, 384)\n",
      "1887_suits_valuation_1.txt_embeddings.npy: (13, 384)\n",
      "1889_metal_tokens_1.txt_embeddings.npy: (11, 384)\n",
      "1889_private_fisheries_protection_2.txt_embeddings.npy: (6, 384)\n",
      "1890_charitable_.endowments_1.txt_embeddings.npy: (22, 384)\n",
      "1890_excise_malt_liquors_2.txt_embeddings.npy: (3, 384)\n",
      "1890_guradians_and_ward_1.txt_embeddings.npy: (75, 384)\n",
      "1890_railway_act_1.txt_embeddings.npy: (184, 384)\n",
      "1893_partition_act_1.txt_embeddings.npy: (11, 384)\n",
      "1894_prisions_1.txt_embeddings.npy: (68, 384)\n",
      "1895_government_grants_1.txt_embeddings.npy: (4, 384)\n",
      "1896_the protection_of_muslim_pilgrims_1.txt_embeddings.npy: (14, 384)\n",
      "1897_general_clause_1.txt_embeddings.npy: (84, 384)\n",
      "\n",
      "🔎 Unique embedding dimensions found: {384, 0}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "embedding_folder = \"data/embeddings\"\n",
    "embedding_files = [f for f in os.listdir(embedding_folder) if f.endswith(\".npy\")]\n",
    "\n",
    "dims = {}\n",
    "for file in embedding_files:\n",
    "    emb = np.load(os.path.join(embedding_folder, file))\n",
    "    if len(emb.shape) == 1:  # single vector\n",
    "        emb = emb.reshape(1, -1)\n",
    "    dims[file] = emb.shape\n",
    "\n",
    "print(\"📊 Embedding dimensions per file:\")\n",
    "for file, shape in dims.items():\n",
    "    print(f\"{file}: {shape}\")\n",
    "\n",
    "unique_dims = set(shape[1] for shape in dims.values())\n",
    "print(\"\\n🔎 Unique embedding dimensions found:\", unique_dims)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d8f05385-52e3-41af-8f1b-fe1c67b4dab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Empty embedding found in 1872_contract_2.txt_embeddings.npy, skipping...\n",
      "✅ Ready embeddings for FAISS. 45 files will be indexed.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "embedding_folder = \"data/embeddings\"\n",
    "embedding_files = [f for f in os.listdir(embedding_folder) if f.endswith(\".npy\")]\n",
    "\n",
    "clean_embeddings = {}\n",
    "\n",
    "for file in embedding_files:\n",
    "    emb = np.load(os.path.join(embedding_folder, file))\n",
    "    \n",
    "    # If single vector, reshape\n",
    "    if len(emb.shape) == 1:\n",
    "        emb = emb.reshape(1, -1)\n",
    "    \n",
    "    # Filter out empty vectors\n",
    "    if emb.shape[1] == 0:\n",
    "        print(f\"⚠️ Empty embedding found in {file}, skipping...\")\n",
    "        continue\n",
    "    \n",
    "    clean_embeddings[file] = emb\n",
    "\n",
    "print(f\"✅ Ready embeddings for FAISS. {len(clean_embeddings)} files will be indexed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0f0fea89-190e-422d-8262-fc463b21e813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ FAISS index created with 2260 vectors.\n",
      "Sample metadata entries: [(\"1872_ marriedwomen'sproperty_6.txt_embeddings.npy\", 0), (\"1872_ marriedwomen'sproperty_6.txt_embeddings.npy\", 1), (\"1872_ marriedwomen'sproperty_6.txt_embeddings.npy\", 2), (\"1872_ marriedwomen'sproperty_6.txt_embeddings.npy\", 3), (\"1872_ marriedwomen'sproperty_6.txt_embeddings.npy\", 4)]\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "\n",
    "# Initialize FAISS index\n",
    "d = list(clean_embeddings.values())[0].shape[1]  # embedding dimension\n",
    "index = faiss.IndexFlatL2(d)  # L2 similarity\n",
    "\n",
    "# Metadata to know which chunk belongs to which file\n",
    "metadata = []\n",
    "\n",
    "for file, emb in clean_embeddings.items():\n",
    "    index.add(emb)\n",
    "    num_chunks = emb.shape[0]\n",
    "    metadata.extend([(file, i) for i in range(num_chunks)])\n",
    "\n",
    "print(f\"✅ FAISS index created with {index.ntotal} vectors.\")\n",
    "print(f\"Sample metadata entries: {metadata[:5]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "786dfcdc-25cd-4709-8584-2171b6f41971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Skipping empty embeddings: 1872_contract_2.txt\n",
      "✅ FAISS index built with 2260 vectors.\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "# --- Step 1: Build FAISS index ---\n",
    "# Get embedding dimension from first non-empty embedding\n",
    "for emb in all_embeddings.values():\n",
    "    if emb.size > 0:\n",
    "        dimension = emb.shape[1] if len(emb.shape) > 1 else len(emb)\n",
    "        break\n",
    "\n",
    "index = faiss.IndexFlatL2(dimension)\n",
    "metadata = []\n",
    "\n",
    "for file, emb in all_embeddings.items():\n",
    "    emb = np.array(emb, dtype='float32')\n",
    "\n",
    "    # Skip empty embeddings\n",
    "    if emb.size == 0:\n",
    "        print(f\"⚠️ Skipping empty embeddings: {file}\")\n",
    "        continue\n",
    "\n",
    "    # Ensure 2D\n",
    "    if len(emb.shape) == 1:\n",
    "        emb = emb.reshape(1, -1)\n",
    "\n",
    "    # Skip embeddings with wrong dimension\n",
    "    if emb.shape[1] != dimension:\n",
    "        print(f\"⚠️ Skipping {file}, dimension mismatch: {emb.shape[1]} vs {dimension}\")\n",
    "        continue\n",
    "\n",
    "    index.add(emb)\n",
    "\n",
    "    # Add metadata\n",
    "    base_file = file.replace(\"_embeddings.npy\", \"\")\n",
    "    for i in range(len(emb)):\n",
    "        metadata.append((base_file, i))\n",
    "\n",
    "print(f\"✅ FAISS index built with {index.ntotal} vectors.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eeb93217-c28c-466f-af30-b142d5de565d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query, top_k=3):\n",
    "    \"\"\"\n",
    "    Search the FAISS index for the top_k most similar chunks to the query.\n",
    "    \"\"\"\n",
    "    # Get embedding for query\n",
    "    query_emb = embed_model.encode([query], convert_to_numpy=True, normalize_embeddings=True)\n",
    "    query_emb = np.array(query_emb, dtype='float32')\n",
    "\n",
    "    # Make sure it's 2D\n",
    "    if len(query_emb.shape) == 1:\n",
    "        query_emb = query_emb.reshape(1, -1)\n",
    "\n",
    "    # Search FAISS\n",
    "    distances, indices = index.search(query_emb, top_k)\n",
    "\n",
    "    results = []\n",
    "    for dist, idx in zip(distances[0], indices[0]):\n",
    "        file, chunk_id = metadata[idx]\n",
    "        chunk_text = chunked_texts[file][chunk_id]\n",
    "        results.append({\n",
    "            \"file\": file,\n",
    "            \"chunk_id\": chunk_id,\n",
    "            \"distance\": dist,\n",
    "            \"text\": chunk_text[:500]  # show first 500 chars\n",
    "        })\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "18e91574-8ef5-4e66-989a-fcc8639ddf2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Result 1 ---\n",
      "File: 1872_ marriedwomen'sproperty_6.txt, Chunk: 10, Distance: 0.7936227917671204\n",
      "d. 8. If a married woman (whether married before or after the first day of January, 1866) possesses separate property, and if any person enters into a contract with her with reference to such property, or on the faith that her obligation arising out of such contract will be satisfied out of her separate property, such person shall be entitled to sue her, and, to the extent of her separate property, to recover against her whatever he might have recovered in such suit had she been unmarried at the\n",
      "\n",
      "--- Result 2 ---\n",
      "File: 1882_property_1.txt, Chunk: 56, Distance: 0.81392502784729\n",
      "he income of the property is insufficient for A's maintenance, and that the sale of the field is necessary, and, acting in good faith, buys the field from A. As between B on the one part and A and the collateral heirs on the other part, a necessity for the sale shall be deemed to have existed. 39. Where a third person has a right to receive maintenance, or a provision for advancement or marriage, from the profits of immoveable property, and such property is transferred the right may be enforced \n",
      "\n",
      "--- Result 3 ---\n",
      "File: 1872_ marriedwomen'sproperty_6.txt, Chunk: 0, Distance: 0.8312393426895142\n",
      "30/08/2025 The Married Women's Property Act, 1874 The Married Women's Property Act, 1874 (ACT NO. Ill OF 1874 ) 2#An Act to explain and amend the law relating to certain married women, and for other purposes. Preamble WHEREAS it is expedient to make such provision as hereinafter appears for the enjoyment of wages and earnings by women married before the first day of January, 1866, and for insurances on lives by persons married before or after that day: And whereas by the [Succession Act, 1925], \n"
     ]
    }
   ],
   "source": [
    "query_text = \"marriage property rights\"\n",
    "results = search(query_text, top_k=3)\n",
    "\n",
    "for i, res in enumerate(results):\n",
    "    print(f\"\\n--- Result {i+1} ---\")\n",
    "    print(f\"File: {res['file']}, Chunk: {res['chunk_id']}, Distance: {res['distance']}\")\n",
    "    print(res['text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7b42e709-3fd8-48f4-8151-1efd9d9f8e5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 Query: marriage property rights\n",
      "\n",
      "--- Result 1 ---\n",
      "File: 1872_ marriedwomen'sproperty_6.txt, Chunk: 10, Distance: 0.7936227917671204\n",
      "d. 8. If a married woman (whether married before or after the first day of January, 1866) possesses separate property, and if any person enters into a contract with her with reference to such property, or on the faith that her obligation arising out of such contract will be satisfied out of her separate property, such person shall be entitled to sue her, and, to the extent of her separate property, to recover against her whatever he might have recovered in such suit had she been unmarried at the\n",
      "\n",
      "--- Result 2 ---\n",
      "File: 1882_property_1.txt, Chunk: 56, Distance: 0.81392502784729\n",
      "he income of the property is insufficient for A's maintenance, and that the sale of the field is necessary, and, acting in good faith, buys the field from A. As between B on the one part and A and the collateral heirs on the other part, a necessity for the sale shall be deemed to have existed. 39. Where a third person has a right to receive maintenance, or a provision for advancement or marriage, from the profits of immoveable property, and such property is transferred the right may be enforced \n",
      "\n",
      "--- Result 3 ---\n",
      "File: 1872_ marriedwomen'sproperty_6.txt, Chunk: 0, Distance: 0.8312393426895142\n",
      "30/08/2025 The Married Women's Property Act, 1874 The Married Women's Property Act, 1874 (ACT NO. Ill OF 1874 ) 2#An Act to explain and amend the law relating to certain married women, and for other purposes. Preamble WHEREAS it is expedient to make such provision as hereinafter appears for the enjoyment of wages and earnings by women married before the first day of January, 1866, and for insurances on lives by persons married before or after that day: And whereas by the [Succession Act, 1925], \n",
      "\n",
      "🔹 Query: contract obligations\n",
      "\n",
      "--- Result 1 ---\n",
      "File: 1877_specific_1.txt, Chunk: 59, Distance: 0.8597980737686157\n",
      "ce. The company takes the land and used it for their railway. Specific performance of the contract to execute the works should be decreed in favour of A. (d) For whom Contracts may be specifically enforced 23. Except as otherwise provided by this Chapter, the specific performance of a contract may be obtained by- (a) any party thereto; (b) the representative in interest, or the principal, of any party thereto: provided that, where the learning, skill, solvency or any personal quality of such par\n",
      "\n",
      "--- Result 2 ---\n",
      "File: 1877_specific_1.txt, Chunk: 65, Distance: 0.8998939990997314\n",
      "the land in an unhusbandlike manner. A cannot enforce specific performance of the contract. A contracts to let, and B contracts to take, an unfinished house, B contracting to finish the house and the lease to contain covenants on the part of A to keep the house in repair. B finishes the house in a very defective manner: he cannot enforce the contract specifically, though A and B may sue each other for compensation for breach of it. to clause (c)- A contracts to let, and B contracts to take, a ho\n",
      "\n",
      "--- Result 3 ---\n",
      "File: 1877_specific_1.txt, Chunk: 75, Distance: 0.9010123610496521\n",
      "B contracting orally to pay rent at taka 120 per mensem. B then sues to enforce specific performance of the contract in writing. He cannot enforce it except with the variations made by the subsequent oral contract. (g) Against whom contracts may be specifically enforced 30/52 30/08/2025 performance of contract to lease Relief against parties and persons claiming under them by subsequent title bdlaws.minlaw.gov.bd/act-print-36.html The Specific Relief Act, 1877 27A. Subject to the provisions of t\n",
      "\n",
      "🔹 Query: religious societies regulations\n",
      "\n",
      "--- Result 1 ---\n",
      "File: 1880_religious_societies_1.txt, Chunk: 0, Distance: 0.772168755531311\n",
      "30/08/2025 Preamble The Religious Societies Act, 1880 The Religious Societies Act, 1880 (ACT NO. | OF 1880 ) An Act to confer certain powers on Religious Societies. WHEREAS it is expedient to simplify the manner in which certain bodies of persons associated for the purpose of maintaining religious worship may hold property acquired for such purpose, and to provide for the dissolution of such bodies and the adjustment of their affairs and for the decision of certain questions relating to such bod\n",
      "\n",
      "--- Result 2 ---\n",
      "File: 1880_religious_societies_1.txt, Chunk: 6, Distance: 0.9216022491455078\n",
      "Saving of certain provisions of instruments Questions may be submitted to High Court Division bdlaws.minlaw.gov.bd/act-print-41.html The Religious Societies Act, 1880 6. Any number not less than three-fifths of the members of any such body as aforesaid may at a meeting convened for the purpose determine that such body shall be dissolved; and thereupon it shall be dissolved forthwith, or at the time then agreed upon; and all necessary steps shall be taken for the disposal and settlement of the pr\n",
      "\n",
      "--- Result 3 ---\n",
      "File: 1880_religious_societies_1.txt, Chunk: 1, Distance: 0.9597898721694946\n",
      "not otherwise provided for bdlaws.minlaw.gov.bd/act-print-41 .html 1. This Act may be called the Religious Societies Act, 1880. It shall extend to the whole of  [Bangladesh] but nothing herein contained shall apply to any Hindus, *[Muslims] or Buddhists, or to any person whom the *[Government] may from time to time by notification in the official Gazette, exclude from the operation of this Act. 2. When any body of persons associated for purpose of maintaining religious worship has acquired, or h\n"
     ]
    }
   ],
   "source": [
    "def batch_search(queries, top_k=3):\n",
    "    \"\"\"\n",
    "    Search multiple queries at once and return top_k results for each.\n",
    "    \"\"\"\n",
    "    results_all = {}\n",
    "    for query in queries:\n",
    "        results = search(query, top_k=top_k)\n",
    "        results_all[query] = results\n",
    "    return results_all\n",
    "\n",
    "# Example usage:\n",
    "queries = [\n",
    "    \"marriage property rights\",\n",
    "    \"contract obligations\",\n",
    "    \"religious societies regulations\"\n",
    "]\n",
    "\n",
    "results_dict = batch_search(queries, top_k=3)\n",
    "\n",
    "# Print results\n",
    "for query, results in results_dict.items():\n",
    "    print(f\"\\n🔹 Query: {query}\")\n",
    "    for i, res in enumerate(results):\n",
    "        print(f\"\\n--- Result {i+1} ---\")\n",
    "        print(f\"File: {res['file']}, Chunk: {res['chunk_id']}, Distance: {res['distance']}\")\n",
    "        print(res['text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "26ac9e49-8c51-4c22-b3f0-acf43e8d4f48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔎 Welcome to the interactive search! Type 'exit' to quit.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your search query:  Marriage rules\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 3 results for: 'Marriage rules'\n",
      "\n",
      "--- Result 1 ---\n",
      "File: 1872_marriage_1.txt, Chunk: 17, Distance: 0.8358\n",
      "person married under this Act who, during the life time of his or her wife or husband, contracts any other marriage, shall be subject to the penalties provided in sections 494 and 495 of the Penal Code for the offence of marrying again during the lifetime of a husband or wife, whatever may be the religion which he or she professed at the time of such second marriage. 17. The Divorce Act shall apply to all marriages contracted under this Act, and any such marriage may be declared null or dissolve\n",
      "\n",
      "--- Result 2 ---\n",
      "File: 1872_marriage_1.txt, Chunk: 16, Distance: 0.9174\n",
      "ook shall at all reasonable times be open for inspection, and shall be admissible as evidence of the truth of the statements therein contained. Certified extracts therefrom shall on application be given by the Registrar on the payment to him by the applicant of a fee to be fixed by the Government for each such extract. 15. Every person who, being at the time married, procures a marriage of himself to be solemnized under this Act, shall be deemed to have committed an offence under section 494 or \n",
      "\n",
      "--- Result 3 ---\n",
      "File: 1872_christianmarriage_3.txt, Chunk: 60, Distance: 0.9622\n",
      "f a person licensed under section 9, and of at least two credible witnesses other than such person, each of the parties shall say to the other   \"| call upon these persons here present to witness that I, A. B., in the presence of Almighty God, and in the name of our Lord Jesus Christ, do take thee, C. D., to be my lawful wedded wife [or husband]\" or words to the like effect: Provided that no marriage shall be certified under this Part when either of the parties intending to be married has not co\n",
      "\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your search query:  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exiting interactive search.\n"
     ]
    }
   ],
   "source": [
    "def interactive_search(top_k=3):\n",
    "    \"\"\"\n",
    "    Interactive search: type a query and get top_k results.\n",
    "    Type 'exit' to quit.\n",
    "    \"\"\"\n",
    "    print(\"🔎 Welcome to the interactive search! Type 'exit' to quit.\\n\")\n",
    "    \n",
    "    while True:\n",
    "        query = input(\"Enter your search query: \")\n",
    "        if query.lower() == \"exit\":\n",
    "            print(\"Exiting interactive search.\")\n",
    "            break\n",
    "        \n",
    "        results = search(query, top_k=top_k)\n",
    "        if not results:\n",
    "            print(\"No results found.\\n\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"\\nTop {top_k} results for: '{query}'\")\n",
    "        for i, res in enumerate(results):\n",
    "            print(f\"\\n--- Result {i+1} ---\")\n",
    "            print(f\"File: {res['file']}, Chunk: {res['chunk_id']}, Distance: {res['distance']:.4f}\")\n",
    "            print(res['text'][:500])  # show first 500 chars\n",
    "        print(\"\\n\" + \"-\"*50 + \"\\n\")\n",
    "\n",
    "# Run the interactive search\n",
    "interactive_search(top_k=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4bd7ef8f-e159-4f8f-ac3a-854a73610f52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔎 Welcome to the interactive search! Type 'exit' to quit.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your search query:  Labour law\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 3 results for: 'Labour law'\n",
      "\n",
      "--- Result 1 ---\n",
      "File: 1890_railway_act_1.txt, Chunk: 85, Distance: 0.9799\n",
      "s (Revision And Declaration) Act, 1973 (Act No. VIII of 1973).] 28/59 05/09/2025 Limitation of hours of work Grant of periodical rest bdlaws.minlaw.gov.bd/act-print-65.html The Railways Act, 1890 71C. (1) The railway servant, other than the railway servant whose employment is essentially intermittent, shall not be employed for more than sixty hours a week on the average in any month. (2) The railway servant whose employment is essentially intermittent shall not be employed for more than eighty-f\n",
      "\n",
      "--- Result 2 ---\n",
      "File: 1890_railway_act_1.txt, Chunk: 86, Distance: 0.9808\n",
      "servants from the provisions of sub-section (1) and sub-section (2) may be made- (a) when such temporary exemptions are necessary to avoid serious interference with the ordinary working of the railway, in cases of accident, actual or threatened, or when urgent work is required to be done to the railway or to rolling-stock or in any emergency which could not have been foreseen or prevented; and (b) in cases of exceptional pressure of work not falling within the scope of clause (a): Provided that \n",
      "\n",
      "--- Result 3 ---\n",
      "File: 1894_prisions_1.txt, Chunk: 27, Distance: 0.9889\n",
      "r are maintained at the expense of the prison shall be subject to a deduction, to be determined by the Superintendent, for the use of implements and the cost of maintenance. 35. (1) No criminal prisoner sentenced to labour or employed on labour at his own desire shall, except on an emergency with the sanction in writing of the Superintendent, be kept to labour for more than nine hours in any one day. (2) The Medical Officer shall from time to time examine the labouring prisoners while they are e\n",
      "\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your search query:  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exiting interactive search.\n"
     ]
    }
   ],
   "source": [
    "def interactive_search_full(top_k=3):\n",
    "    \"\"\"\n",
    "    Interactive search: type a query and get top_k results.\n",
    "    Shows the full text of each matching chunk.\n",
    "    Type 'exit' to quit.\n",
    "    \"\"\"\n",
    "    print(\"🔎 Welcome to the interactive search! Type 'exit' to quit.\\n\")\n",
    "    \n",
    "    while True:\n",
    "        query = input(\"Enter your search query: \")\n",
    "        if query.lower() == \"exit\":\n",
    "            print(\"Exiting interactive search.\")\n",
    "            break\n",
    "        \n",
    "        results = search(query, top_k=top_k)\n",
    "        if not results:\n",
    "            print(\"No results found.\\n\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"\\nTop {top_k} results for: '{query}'\")\n",
    "        for i, res in enumerate(results):\n",
    "            print(f\"\\n--- Result {i+1} ---\")\n",
    "            print(f\"File: {res['file']}, Chunk: {res['chunk_id']}, Distance: {res['distance']:.4f}\")\n",
    "            print(res['text'])  # show full chunk\n",
    "        print(\"\\n\" + \"-\"*50 + \"\\n\")\n",
    "\n",
    "# Run the interactive search with full chunks\n",
    "interactive_search_full(top_k=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f9c79969-4e8a-4605-9f53-be8b0b975e1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: click in c:\\users\\asus\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from nltk) (8.1.8)\n",
      "Requirement already satisfied: joblib in c:\\users\\asus\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\asus\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from nltk) (2025.9.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\asus\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\asus\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 0.3/1.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.5/1.5 MB 8.2 MB/s  0:00:00\n",
      "Installing collected packages: nltk\n",
      "Successfully installed nltk-3.9.1\n"
     ]
    }
   ],
   "source": [
    "! pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "346515f4-a0e7-4ca5-b484-e2546151f084",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Asus\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "def chunk_text_sentences(text, chunk_size=800, overlap=200):\n",
    "    \"\"\"\n",
    "    Splits text into chunks of approx chunk_size chars, ending at sentence boundaries,\n",
    "    with specified overlap for context.\n",
    "    \"\"\"\n",
    "    sentences = sent_tokenize(text)\n",
    "    chunks = []\n",
    "    current_chunk = \"\"\n",
    "    \n",
    "    for sent in sentences:\n",
    "        if len(current_chunk) + len(sent) + 1 <= chunk_size:\n",
    "            current_chunk += \" \" + sent\n",
    "        else:\n",
    "            chunks.append(current_chunk.strip())\n",
    "            # Start next chunk with overlap\n",
    "            current_chunk = \" \".join(sentences[max(0, sentences.index(sent)-overlap//chunk_size):sentences.index(sent)+1])\n",
    "    \n",
    "    if current_chunk:\n",
    "        chunks.append(current_chunk.strip())\n",
    "    \n",
    "    return chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c2ea3094-d82d-41be-afd4-5dfb21dd862d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Result 1 ---\n",
      "File: 1872_ marriedwomen'sproperty_6.txt, Chunk: 10, Distance: 0.7936\n",
      "re the first day of April, 1923. CHAPTER IV LEGAL PROCEEDINGS BY AND AGAINST MARRIED WOMEN 7. A married woman may maintain a suit in her own name for the recovery of property of any description which by force of the said  [Succession Act, 1925], or of this Act, is her separate property; and she shall have, in her own name, the same remedies, both civil and criminal, against all persons, for the protection and security of such property, as if she were unmarried, and she shall be liable to such suits, processes and orders in respect of such property as she would be liable to if she were unmarried. 8. If a married woman (whether married before or after the first day of January, 1866) possesses separate property, and if any person enters into a contract with her with reference to such property d. 8. If a married woman (whether married before or after the first day of January, 1866) possesses separate property, and if any person enters into a contract with her with reference to such propert...\n",
      "\n",
      "--- Result 2 ---\n",
      "File: 1882_property_1.txt, Chunk: 56, Distance: 0.8139\n",
      ", they shall, as between the transferee on the one part and the transferor and other persons (if any) affected by the transfer on the other part, be deemed to have existed, if the transferee, after using reasonable care to ascertain the existence of such circumstances, has acted in good faith. Illustration A, a Hindu widow, whose husband has left collateral heirs, alleging that the property held by her as such is insufficient for her maintenance, agrees, for purposes neither religious nor charitable, to sell a field, part of such property, to B. B satisfies himself by reasonable enquiry that the income of the property is insufficient for A's maintenance, and that the sale of the field is necessary, and, acting in good faith, buys the field from A. As between B on the one part and A and the he income of the property is insufficient for A's maintenance, and that the sale of the field is necessary, and, acting in good faith, buys the field from A. As between B on the one part and A and th...\n",
      "\n",
      "--- Result 3 ---\n",
      "File: 1872_ marriedwomen'sproperty_6.txt, Chunk: 0, Distance: 0.8312\n",
      "30/08/2025 The Married Women's Property Act, 1874 The Married Women's Property Act, 1874 (ACT NO. Ill OF 1874 ) 2#An Act to explain and amend the law relating to certain married women, and for other purposes. Preamble WHEREAS it is expedient to make such provision as hereinafter appears for the enjoyment of wages and earnings by women married before the first day of January, 1866, and for insurances on lives by persons married before or after that day: And whereas by the [Succession Act, 1925], section 4, it is enacted that no person shall by marriage acquire any interest in the property of the person whom he or she marries, nor become incapable of doing any act in respect of his or her own property, which he or she could have done, if unmarried: And whereas by force of the said Act all wo e person whom he or she marries, nor become incapable of doing any act in respect of his or her own property, which he or she could have done, if unmarried: And whereas by force of the said Act all w...\n"
     ]
    }
   ],
   "source": [
    "def display_search_results(results, chunked_texts, context_chunks=1):\n",
    "    \"\"\"\n",
    "    Display search results with neighboring chunk context.\n",
    "    \n",
    "    results: list of dicts from search function\n",
    "    chunked_texts: dict of all chunked texts\n",
    "    context_chunks: how many previous and next chunks to show\n",
    "    \"\"\"\n",
    "    for i, res in enumerate(results):\n",
    "        file = res[\"file\"]\n",
    "        chunk_id = res[\"chunk_id\"]\n",
    "        distance = res[\"distance\"]\n",
    "        \n",
    "        # Determine the chunk range for context\n",
    "        start = max(0, chunk_id - context_chunks)\n",
    "        end = min(len(chunked_texts[file]), chunk_id + context_chunks + 1)\n",
    "        \n",
    "        # Combine chunks into one string\n",
    "        combined_text = \" \".join(chunked_texts[file][start:end])\n",
    "        \n",
    "        print(f\"\\n--- Result {i+1} ---\")\n",
    "        print(f\"File: {file}, Chunk: {chunk_id}, Distance: {distance:.4f}\")\n",
    "        print(combined_text[:1000] + \"...\")  # show first 1000 chars for readability\n",
    "\n",
    "# Example usage\n",
    "query_text = \"marriage property rights\"\n",
    "results = search(query_text, top_k=3)\n",
    "display_search_results(results, chunked_texts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6358d552-f48a-43ab-81a0-d19a53993113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Result 1 ---\n",
      "File: 1872_ marriedwomen'sproperty_6.txt, Chunk: 10, Distance: 0.7936\n",
      "re the first day of April, 1923. CHAPTER IV LEGAL PROCEEDINGS BY AND AGAINST MARRIED WOMEN 7. A married woman may maintain a suit in her own name for the recovery of \u001b[93mproperty\u001b[0m of any description which by force of the said  [Succession Act, 1925], or of this Act, is her separate \u001b[93mproperty\u001b[0m; and she shall have, in her own name, the same remedies, both civil and criminal, against all persons, for the protection and security of such \u001b[93mproperty\u001b[0m, as if she were unmarried, and she shall be liable to such suits, processes and orders in respect of such \u001b[93mproperty\u001b[0m as she would be liable to if she were unmarried. 8. If a married woman (whether married before or after the first day of January, 1866) possesses separate \u001b[93mproperty\u001b[0m, and if any person enters into a contract with her with reference to such \u001b[93mproperty\u001b[0m d. 8. If a married woman (whether married before or after the first day of January, 1866) possesses separate \u001b[93mproperty\u001b[0m, and if any person...\n",
      "\n",
      "--- Result 2 ---\n",
      "File: 1882_property_1.txt, Chunk: 56, Distance: 0.8139\n",
      ", they shall, as between the transferee on the one part and the transferor and other persons (if any) affected by the transfer on the other part, be deemed to have existed, if the transferee, after using reasonable care to ascertain the existence of such circumstances, has acted in good faith. Illustration A, a Hindu widow, whose husband has left collateral heirs, alleging that the \u001b[93mproperty\u001b[0m held by her as such is insufficient for her maintenance, agrees, for purposes neither religious nor charitable, to sell a field, part of such \u001b[93mproperty\u001b[0m, to B. B satisfies himself by reasonable enquiry that the income of the \u001b[93mproperty\u001b[0m is insufficient for A's maintenance, and that the sale of the field is necessary, and, acting in good faith, buys the field from A. As between B on the one part and A and the he income of the \u001b[93mproperty\u001b[0m is insufficient for A's maintenance, and that the sale of the field is necessary, and, acting in good faith, buys the field from A. As be...\n",
      "\n",
      "--- Result 3 ---\n",
      "File: 1872_ marriedwomen'sproperty_6.txt, Chunk: 0, Distance: 0.8312\n",
      "30/08/2025 The Married Women's \u001b[93mProperty\u001b[0m Act, 1874 The Married Women's \u001b[93mProperty\u001b[0m Act, 1874 (ACT NO. Ill OF 1874 ) 2#An Act to explain and amend the law relating to certain married women, and for other purposes. Preamble WHEREAS it is expedient to make such provision as hereinafter appears for the enjoyment of wages and earnings by women married before the first day of January, 1866, and for insurances on lives by persons married before or after that day: And whereas by the [Succession Act, 1925], section 4, it is enacted that no person shall by \u001b[93mmarriage\u001b[0m acquire any interest in the \u001b[93mproperty\u001b[0m of the person whom he or she marries, nor become incapable of doing any act in respect of his or her own \u001b[93mproperty\u001b[0m, which he or she could have done, if unmarried: And whereas by force of the said Act all wo e person whom he or she marries, nor become incapable of doing any act in respect of his or her own \u001b[93mproperty\u001b[0m, which he or she could have done, if...\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def highlight_text(text, query):\n",
    "    \"\"\"\n",
    "    Highlights all occurrences of query words in the text (case-insensitive).\n",
    "    \"\"\"\n",
    "    words = query.split()\n",
    "    for word in words:\n",
    "        # Use regex to match whole words, case-insensitive\n",
    "        text = re.sub(f\"(?i)({re.escape(word)})\", r\"\\033[93m\\1\\033[0m\", text)\n",
    "    return text\n",
    "\n",
    "def display_search_results_highlight(results, chunked_texts, query, context_chunks=1):\n",
    "    \"\"\"\n",
    "    Display search results with neighboring chunk context and highlighted query.\n",
    "    \"\"\"\n",
    "    for i, res in enumerate(results):\n",
    "        file = res[\"file\"]\n",
    "        chunk_id = res[\"chunk_id\"]\n",
    "        distance = res[\"distance\"]\n",
    "        \n",
    "        # Determine the chunk range for context\n",
    "        start = max(0, chunk_id - context_chunks)\n",
    "        end = min(len(chunked_texts[file]), chunk_id + context_chunks + 1)\n",
    "        \n",
    "        # Combine chunks into one string\n",
    "        combined_text = \" \".join(chunked_texts[file][start:end])\n",
    "        highlighted_text = highlight_text(combined_text, query)\n",
    "        \n",
    "        print(f\"\\n--- Result {i+1} ---\")\n",
    "        print(f\"File: {file}, Chunk: {chunk_id}, Distance: {distance:.4f}\")\n",
    "        print(highlighted_text[:1000] + \"...\")  # show first 1000 chars\n",
    "\n",
    "# Example usage\n",
    "query_text = \"marriage property rights\"\n",
    "results = search(query_text, top_k=3)\n",
    "display_search_results_highlight(results, chunked_texts, query_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b6dd4d16-6443-4a30-b9ba-8a1b4b56613d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ FAISS index saved!\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "os.makedirs(\"data/index\", exist_ok=True)\n",
    "\n",
    "# Save FAISS index\n",
    "faiss.write_index(index, \"data/index/faiss_index.bin\")\n",
    "print(\"✅ FAISS index saved!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "57f1cb77-1d42-481e-9124-89b160968b8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Metadata saved!\n"
     ]
    }
   ],
   "source": [
    "# Save metadata dictionary (filename + chunk_id for each vector)\n",
    "with open(\"data/index/metadata.pkl\", \"wb\") as f:\n",
    "    pickle.dump(metadata, f)\n",
    "\n",
    "print(\"✅ Metadata saved!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "39cb527e-b657-410f-b68e-4eaf8b1cd789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ FAISS index and metadata loaded!\n"
     ]
    }
   ],
   "source": [
    "# Load FAISS index\n",
    "index = faiss.read_index(\"data/index/faiss_index.bin\")\n",
    "\n",
    "# Load metadata\n",
    "with open(\"data/index/metadata.pkl\", \"rb\") as f:\n",
    "    metadata = pickle.load(f)\n",
    "\n",
    "print(\"✅ FAISS index and metadata loaded!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5c560a3e-5b1c-4b14-8936-f0ab39f3d0ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Merging chunks done. Sample merged chunks from first file:\n",
      "\n",
      "--- Merged Chunk 1 ---\n",
      "30/08/2025 The Married Women's Property Act, 1874 The Married Women's Property Act, 1874 (ACT NO. Ill OF 1874 ) 2#An Act to explain and amend the law relating to certain married women, and for other purposes. Preamble WHEREAS it is expedient to make such provision as hereinafter appears for the enjoyment of wages and earnings by women married before the first day of January, 1866, and for insurances on lives by persons married before or after that day: And whereas by the [Succession Act, 1925], ...\n",
      "\n",
      "--- Merged Chunk 2 ---\n",
      "ves: CHAPTER | PRELIMINARY Short title 1. This Act may be called the Married Women's Property Act, 1874. Extent and 2. It extends to the whole of Bangladesh. application bdlaws.minlaw.gov.bd/act-print-30.html 1/6 30/08/2025 [Repealed] Married women's earnings to be their separate property bdlaws.minlaw.gov.bd/act-print-30.html The Married Women's Property Act, 1874 But nothing herein contained applies to any married woman who at the time of her marriage professed the Hindu, *[Muslim], Buddhist, ...\n"
     ]
    }
   ],
   "source": [
    "# 🔹 Function to merge consecutive chunks into larger passages\n",
    "def merge_chunks(chunks, max_merge=2):\n",
    "    \"\"\"\n",
    "    Merge consecutive chunks for better context.\n",
    "    max_merge = how many consecutive chunks to merge.\n",
    "    \"\"\"\n",
    "    merged = []\n",
    "    i = 0\n",
    "    while i < len(chunks):\n",
    "        merged_chunk = chunks[i]\n",
    "        for j in range(1, max_merge):\n",
    "            if i + j < len(chunks):\n",
    "                merged_chunk += \" \" + chunks[i + j]\n",
    "        merged.append(merged_chunk.strip())\n",
    "        i += max_merge  # skip merged chunks\n",
    "    return merged\n",
    "\n",
    "# 🔹 Apply merged chunks to all documents\n",
    "merged_chunked_texts = {}\n",
    "for filename, chunks in chunked_texts.items():\n",
    "    merged_chunked_texts[filename] = merge_chunks(chunks, max_merge=2)\n",
    "\n",
    "print(\"✅ Merging chunks done. Sample merged chunks from first file:\")\n",
    "first_file = list(merged_chunked_texts.keys())[0]\n",
    "for i, chunk in enumerate(merged_chunked_texts[first_file][:2]):\n",
    "    print(f\"\\n--- Merged Chunk {i+1} ---\\n{chunk[:500]}...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c46bbe24-4665-4e68-b1b7-df0ac3410dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/index/chunked_texts.pkl\", \"wb\") as f:\n",
    "    pickle.dump(chunked_texts, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a99796b0-05e3-4cca-8b49-f3b42202b14c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "[\"1872_ marriedwomen'sproperty_6.txt\", '1872_christianmarriage_3.txt', '1872_contract_2.txt', '1872_foreign_recruting_7.txt', '1872_majority_9.txt']\n",
      "\n",
      "Number of chunks in 1872_ marriedwomen'sproperty_6.txt: 16\n",
      "First chunk preview:\n",
      " 30/08/2025 The Married Women's Property Act, 1874 The Married Women's Property Act, 1874 (ACT NO. Ill OF 1874 ) 2#An Act to explain and amend the law relating to certain married women, and for other purposes. Preamble WHEREAS it is expedient to make such provision as hereinafter appears for the enjoyment of wages and earnings by women married before the first day of January, 1866, and for insurances on lives by persons married before or after that day: And whereas by the [Succession Act, 1925], \n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Load the file\n",
    "with open(\"data/index/chunked_texts.pkl\", \"rb\") as f:\n",
    "    loaded_chunks = pickle.load(f)\n",
    "\n",
    "# Check type and keys\n",
    "print(type(loaded_chunks))           # Should be <class 'dict'>\n",
    "print(list(loaded_chunks.keys())[:5])  # Show first 5 filenames\n",
    "\n",
    "# Inspect one file's chunks\n",
    "first_file = list(loaded_chunks.keys())[0]\n",
    "print(f\"\\nNumber of chunks in {first_file}: {len(loaded_chunks[first_file])}\")\n",
    "print(\"First chunk preview:\\n\", loaded_chunks[first_file][0][:500])  # first 500 chars\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075725fc-c12d-412f-a007-2975618628cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
